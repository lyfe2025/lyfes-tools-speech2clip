#!/usr/bin/env python3
"""
Speech2Clip CLI Demo - å‘½ä»¤è¡Œæ¼”ç¤ºç‰ˆæœ¬
æ”¯æŒ Google/Whisper ä¸¤ç§è¯­éŸ³è¯†åˆ«å¼•æ“ï¼Œé»˜è®¤æœ¬åœ°Whisper
å¯é€šè¿‡ --device/-d å‚æ•°æŒ‡å®šéº¦å…‹é£ç¼–å·
"""

import sys
import time
import pyperclip
import argparse
from speech_recognizer import SpeechRecognizer, RecognitionEngine
import pyaudio
import wave
import numpy as np
from opencc import OpenCC
import warnings

warnings.filterwarnings("ignore", category=UserWarning)

WHISPER_MODELS = ['tiny', 'base', 'small', 'medium', 'large']

cc = OpenCC('t2s')  # ç¹ä½“è½¬ç®€ä½“

def list_devices():
    try:
        import speech_recognition as sr
        print('å¯ç”¨éŸ³é¢‘è¾“å…¥è®¾å¤‡åˆ—è¡¨:')
        for i, name in enumerate(sr.Microphone.list_microphone_names()):
            print(f'{i}: {name}')
    except Exception as e:
        print(f'âŒ è®¾å¤‡åˆ—è¡¨è·å–å¤±è´¥: {e}')

def custom_record_with_silence_detection(device_index=None, silence_seconds=5, max_seconds=10, threshold=500):
    """
    ç”¨pyaudioé‡‡é›†éŸ³é¢‘æµï¼Œè¿ç»­silence_secondsé™éŸ³åˆ™åœæ­¢ï¼Œå¦åˆ™æœ€é•¿max_secondsç§’ã€‚
    thresholdä¸ºé™éŸ³åˆ¤å®šé˜ˆå€¼ï¼ˆå¯æ ¹æ®å®é™…è°ƒæ•´ï¼‰ã€‚
    è¿”å›éŸ³é¢‘æ•°æ®bytesã€‚
    """
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, input_device_index=device_index, frames_per_buffer=CHUNK)
    print(f"ğŸ¤ å¼€å§‹è‡ªå®šä¹‰å½•éŸ³ï¼Œæœ€é•¿{max_seconds}ç§’ï¼Œé™éŸ³{silence_seconds}ç§’è‡ªåŠ¨åœæ­¢...")
    frames = []
    silent_chunks = 0
    max_chunks = int(RATE / CHUNK * max_seconds)
    silence_chunk_limit = int(RATE / CHUNK * silence_seconds)
    for i in range(max_chunks):
        data = stream.read(CHUNK, exception_on_overflow=False)
        frames.append(data)
        audio_np = np.frombuffer(data, dtype=np.int16)
        rms = np.sqrt(np.mean(audio_np ** 2))
        if rms < threshold:
            silent_chunks += 1
        else:
            silent_chunks = 0
        if silent_chunks >= silence_chunk_limit:
            print(f"ğŸ›‘ æ£€æµ‹åˆ°è¿ç»­{silence_seconds}ç§’é™éŸ³ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³ã€‚")
            break
    stream.stop_stream()
    stream.close()
    p.terminate()
    # ä¿å­˜ä¸ºwav
    wf = wave.open('test_record.wav', 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()
    print("å½•éŸ³å·²ä¿å­˜ä¸º test_record.wavï¼Œè¯·ç”¨æ’­æ”¾å™¨è¯•å¬ã€‚")
    # è¿”å›éŸ³é¢‘æ•°æ®bytes
    return b''.join(frames)

def main():
    parser = argparse.ArgumentParser(description='Speech2Clip CLI Demo')
    parser.add_argument('engine', nargs='?', default='whisper', choices=['whisper', 'google'], help='è¯­éŸ³è¯†åˆ«å¼•æ“')
    parser.add_argument('--device', '-d', type=int, default=None, help='éº¦å…‹é£è®¾å¤‡ç¼–å·')
    parser.add_argument('--list-devices', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨éŸ³é¢‘è¾“å…¥è®¾å¤‡')
    parser.add_argument('--whisper-model', type=str, default='base', choices=WHISPER_MODELS, help='Whisperæ¨¡å‹å')
    args = parser.parse_args()

    if args.list_devices:
        list_devices()
        return

    print("=" * 50)
    print("ğŸ¤ Speech2Clip CLI Demo")
    print("=" * 50)

    engine = RecognitionEngine.WHISPER if args.engine == 'whisper' else RecognitionEngine.GOOGLE
    print(f"ğŸ”„ è¯†åˆ«å¼•æ“: {'Whisper æœ¬åœ°è¯†åˆ« (ç¦»çº¿)' if engine == RecognitionEngine.WHISPER else 'Google äº‘ç«¯è¯†åˆ« (éœ€è”ç½‘)'}")
    if engine == RecognitionEngine.WHISPER:
        print(f"ğŸ§  Whisperæ¨¡å‹: {args.whisper_model}")
    if args.device is not None:
        print(f"ğŸ§ ä½¿ç”¨éº¦å…‹é£è®¾å¤‡ç¼–å·: {args.device}")

    recognizer = SpeechRecognizer()
    recognizer.set_engine(engine)
    # è®¾ç½®whisperæ¨¡å‹
    if engine == RecognitionEngine.WHISPER:
        recognizer.engine_configs[RecognitionEngine.WHISPER]['model'] = args.whisper_model

    # æ£€æŸ¥éº¦å…‹é£
    try:
        import speech_recognition as sr
        microphone = sr.Microphone(device_index=args.device)
        print(f"âœ… éº¦å…‹é£å·²æ£€æµ‹åˆ°: {microphone.device_index} - {sr.Microphone.list_microphone_names()[microphone.device_index]}")
    except Exception as e:
        print(f"âŒ éº¦å…‹é£æ£€æµ‹å¤±è´¥: {e}")
        print("ğŸ“ æ³¨æ„ï¼šåœ¨è¿œç¨‹ç¯å¢ƒä¸­ï¼Œéº¦å…‹é£å¯èƒ½ä¸å¯ç”¨")
        print("ğŸ”„ å°†ä½¿ç”¨æ¨¡æ‹Ÿæ–‡æœ¬è¿›è¡Œæ¼”ç¤º...")
        demo_text = "è¿™æ˜¯ä¸€ä¸ªSpeech2Clipæ¼”ç¤ºæ–‡æœ¬ï¼Œå±•ç¤ºäº†è¯­éŸ³è½¬æ–‡æœ¬å¹¶å¤åˆ¶åˆ°å‰ªè´´æ¿çš„åŠŸèƒ½ã€‚"
        print(f"\nğŸ“ æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ: {demo_text}")
        try:
            pyperclip.copy(demo_text)
            print("âœ… æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
            clipboard_content = pyperclip.paste()
            print(f"ğŸ“‹ å‰ªè´´æ¿å†…å®¹: {clipboard_content}")
        except Exception as e:
            print(f"âŒ å‰ªè´´æ¿æ“ä½œå¤±è´¥: {e}")
        return

    print("\nğŸ™ï¸ å‡†å¤‡å¼€å§‹è¯­éŸ³è¯†åˆ«æ¼”ç¤º...")
    print("â° 5ç§’åå¼€å§‹å½•éŸ³ï¼Œè¯·å‡†å¤‡è¯´è¯...")
    for i in range(5, 0, -1):
        print(f"â±ï¸ {i}...")
        time.sleep(1)

    try:
        print("\nğŸ”´ å¼€å§‹å½•éŸ³...")
        audio_data = custom_record_with_silence_detection(device_index=args.device, silence_seconds=5, max_seconds=10, threshold=500)
        # é€å…¥è¯†åˆ«ï¼ˆä¸å†ç”¨å†…å­˜æµç»“æœå†™å‰ªè´´æ¿ï¼‰
        text, confidence = recognizer.recognize_from_audio_data(audio_data, language='zh')
        if text:
            print(f"âœ… è¯†åˆ«æˆåŠŸ: {text}")
            print(f"ğŸ”¢ ç½®ä¿¡åº¦: {confidence:.2f}")
        else:
            print("âŒ è¯†åˆ«å¤±è´¥æˆ–æ— è¯­éŸ³å†…å®¹")
        # ç”¨æ–‡ä»¶æ–¹å¼å†è¯†åˆ«ä¸€æ¬¡ï¼Œå¹¶å†™å…¥å‰ªè´´æ¿
        file_text, file_conf = recognizer.recognize_from_file('test_record.wav', language='zh')
        simple_text = cc.convert(file_text) if file_text else ''
        print(f"[æ–‡ä»¶è¯†åˆ«] ç»“æœ: {simple_text}, ç½®ä¿¡åº¦: {file_conf}")
        if simple_text:
            try:
                pyperclip.copy(simple_text)
                print("ğŸ“‹ [æ–‡ä»¶è¯†åˆ«] æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
                clipboard_content = pyperclip.paste()
                print(f"ğŸ“‹ å‰ªè´´æ¿å†…å®¹: {clipboard_content}")
            except Exception as e:
                print(f"âŒ å‰ªè´´æ¿æ“ä½œå¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ è¯­éŸ³è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {e}")
        if engine == RecognitionEngine.GOOGLE:
            print("ğŸ’¡ å¯èƒ½éœ€è¦ç½‘ç»œè¿æ¥æ¥ä½¿ç”¨Googleè¯­éŸ³è¯†åˆ«")
        elif engine == RecognitionEngine.WHISPER:
            print("ğŸ’¡ Whisperæ¨¡å‹éœ€æœ¬åœ°ç®—åŠ›ï¼Œé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹")

    print("\n" + "=" * 50)
    print("ğŸ‰ Speech2Clip CLI Demo æ¼”ç¤ºå®Œæˆ")
    print("=" * 50)

if __name__ == "__main__":
    main()